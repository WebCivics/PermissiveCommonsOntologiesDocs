{
    "componentChunkName": "component---node-modules-gatsby-theme-primer-wiki-src-templates-post-query-js",
    "path": "/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka/",
    "result": {"data":{"mdx":{"id":"09eb6a0d-4f45-5b9f-bab7-18d311b17256","tableOfContents":{"items":[{"url":"#introduction","title":"INTRODUCTION"}]},"fields":{"title":"INTRODUCTION","slug":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka/","url":"https://pct-devdocs.webcivics.org/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka/","editUrl":"https://github.com/WebCivics/PermissiveCommonsOntologiesDocs/tree/main/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka.md","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023","gitCreatedAt":"2023-01-04T00:28:43.000Z","shouldShowTitle":false},"frontmatter":{"title":"","description":null,"imageAlt":null,"tags":[],"date":null,"dateModified":null,"language":null,"seoTitle":null,"image":null},"body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Content Sourced from the  \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/intro\"\n  }, \"Apache Kafka\"), \" Website (link also provided),\"), mdx(\"h1\", {\n    \"id\": \"introduction\"\n  }, \"INTRODUCTION\"), mdx(\"p\", null, \"Everything you need to know about Kafka in 10 minutes : \"), mdx(\"iframe\", {\n    width: \"560\",\n    height: \"315\",\n    src: \"https://www.youtube.com/embed/FKgi3n-FyNU\",\n    title: \"YouTube video player\",\n    frameBorder: \"0\",\n    allow: \"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\",\n    allowFullScreen: true\n  }), mdx(\"h4\", {\n    \"id\": \"apache-kafka-is-an-event-streaming-platform-what-does-that-mean\"\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_platform\"\n  }, \"Apache Kafka\\xAE is an event streaming platform. What does that mean?\")), mdx(\"p\", null, \"Kafka combines three key capabilities so you can implement\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/powered-by\"\n  }, \"your use cases\"), \"\\xA0for event streaming end-to-end with a single battle-tested solution:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"To\\xA0\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"publish\"), \"\\xA0(write) and\\xA0\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"subscribe to\"), \"\\xA0(read) streams of events, including continuous import/export of your data from other systems.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"To\\xA0\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"store\"), \"\\xA0streams of events durably and reliably for as long as you want.\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"To\\xA0\", mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"process\"), \"\\xA0streams of events as they occur or retrospectively.\")), mdx(\"p\", null, \"And all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner. Kafka can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud. You can choose between self-managing your Kafka environments and using fully managed services offered by a variety of vendors.\"), mdx(\"h4\", {\n    \"id\": \"how-does-kafka-work-in-a-nutshell\"\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_nutshell\"\n  }), mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_nutshell\"\n  }, \"How does Kafka work in a nutshell?\")), mdx(\"p\", null, \"Kafka is a distributed system consisting of\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"servers\"), \"\\xA0and\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"clients\"), \"\\xA0that communicate via a high-performance\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/protocol.html\"\n  }, \"TCP network protocol\"), \". It can be deployed on bare-metal hardware, virtual machines, and containers in on-premise as well as cloud environments.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Servers\"), \": Kafka is run as a cluster of one or more servers that can span multiple datacenters or cloud regions. Some of these servers form the storage layer, called the brokers. Other servers run\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/documentation/#connect\"\n  }, \"Kafka Connect\"), \"\\xA0to continuously import and export data as event streams to integrate Kafka with your existing systems such as relational databases as well as other Kafka clusters. To let you implement mission-critical use cases, a Kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.\"), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Clients\"), \": They allow you to write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures. Kafka ships with some such clients included, which are augmented by\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://cwiki.apache.org/confluence/display/KAFKA/Clients\"\n  }, \"dozens of clients\"), \"\\xA0provided by the Kafka community: clients are available for Java and Scala including the higher-level\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/documentation/streams/\"\n  }, \"Kafka Streams\"), \"\\xA0library, for Go, Python, C/C++, and many other programming languages as well as REST APIs.\"), mdx(\"h4\", {\n    \"id\": \"what-is-event-streaming\"\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_streaming\"\n  }, \"What is event streaming?\")), mdx(\"p\", null, \"Event streaming is the digital equivalent of the human body's central nervous system. It is the technological foundation for the 'always-on' world where businesses are increasingly software-defined and automated, and where the user of software is more software.\"), mdx(\"p\", null, \"Technically speaking, event streaming is the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events; storing these event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in real-time as well as retrospectively; and routing the event streams to different destination technologies as needed. Event streaming thus ensures a continuous flow and interpretation of data so that the right information is at the right place, at the right time.\"), mdx(\"h4\", {\n    \"id\": \"what-can-i-use-event-streaming-for\"\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_usage\"\n  }), mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_usage\"\n  }, \"What can I use event streaming for?\")), mdx(\"p\", null, \"Event streaming is applied to a\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/powered-by\"\n  }, \"wide variety of use cases\"), \"\\xA0across a plethora of industries and organizations. Its many examples include:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To process payments and financial transactions in real-time, such as in stock exchanges, banks, and insurances.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To track and monitor cars, trucks, fleets, and shipments in real-time, such as in logistics and the automotive industry.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To continuously capture and analyze sensor data from IoT devices or other equipment, such as in factories and wind parks.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To collect and immediately react to customer interactions and orders, such as in retail, the hotel and travel industry, and mobile applications.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To monitor patients in hospital care and predict changes in condition to ensure timely treatment in emergencies.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To connect, store, and make available data produced by different divisions of a company.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"To serve as the foundation for data platforms, event-driven architectures, and microservices.\")), mdx(\"h4\", {\n    \"id\": \"main-concepts-and-terminology\"\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_concepts_and_terms\"\n  }), mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://kafka.apache.org/intro#intro_concepts_and_terms\"\n  }, \"Main Concepts and Terminology\")), mdx(\"p\", null, \"An\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"event\"), \"\\xA0records the fact that \\\"something happened\\\" in the world or in your business. It is also called record or message in the documentation. When you read or write data to Kafka, you do this in the form of events. Conceptually, an event has a key, value, timestamp, and optional metadata headers. Here's an example event:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Event key: \\\"Alice\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Event value: \\\"Made a payment of $200 to Bob\\\"\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Event timestamp: \\\"Jun. 25, 2020 at 2:06 p.m.\\\"\")), mdx(\"p\", null, mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Producers\"), \"\\xA0are those client applications that publish (write) events to Kafka, and\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"consumers\"), \"\\xA0are those that subscribe to (read and process) these events. In Kafka, producers and consumers are fully decoupled and agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for. For example, producers never need to wait for consumers. Kafka provides various\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/documentation/#semantics\"\n  }, \"guarantees\"), \"\\xA0such as the ability to process events exactly-once.\"), mdx(\"p\", null, \"Events are organized and durably stored in\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"topics\"), \". Very simplified, a topic is similar to a folder in a filesystem, and the events are the files in that folder. An example topic name could be \\\"payments\\\". Topics in Kafka are always multi-producer and multi-subscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers that subscribe to these events. Events in a topic can be read as often as needed\\u2014unlike traditional messaging systems, events are not deleted after consumption. Instead, you define for how long Kafka should retain your events through a per-topic configuration setting, after which old events will be discarded. Kafka's performance is effectively constant with respect to data size, so storing data for a long time is perfectly fine.\"), mdx(\"p\", null, \"Topics are\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"partitioned\"), \", meaning a topic is spread over a number of \\\"buckets\\\" located on different Kafka brokers. This distributed placement of your data is very important for scalability because it allows client applications to both read and write the data from/to many brokers at the same time. When a new event is published to a topic, it is actually appended to one of the topic's partitions. Events with the same event key (e.g., a customer or vehicle ID) are written to the same partition, and Kafka\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/documentation/#semantics\"\n  }, \"guarantees\"), \"\\xA0that any consumer of a given topic-partition will always read that partition's events in exactly the same order as they were written.\"), mdx(\"img\", {\n    \"src\": \"https://kafka.apache.org/images/streams-and-tables-p1_p4.png\",\n    \"alt\": null\n  }), mdx(\"p\", null, \"Figure: This example topic has four partitions P1\\u2013P4. Two different producer clients are publishing, independently from each other, new events to the topic by writing events over the network to the topic's partitions. Events with the same key (denoted by their color in the figure) are written to the same partition. Note that both producers can write to the same partition if appropriate.\"), mdx(\"p\", null, \"To make your data fault-tolerant and highly-available, every topic can be\\xA0\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"replicated\"), \", even across geo-regions or datacenters, so that there are always multiple brokers that have a copy of the data just in case things go wrong, you want to do maintenance on the brokers, and so on. A common production setting is a replication factor of 3, i.e., there will always be three copies of your data. This replication is performed at the level of topic-partitions.\"), mdx(\"p\", null, \"This primer should be sufficient for an introduction. The\\xA0\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/documentation/#design\"\n  }, \"Design\"), \"\\xA0section of the documentation explains Kafka's various concepts in full detail, if you are interested.\"), mdx(\"p\", null, \"Source: \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://kafka.apache.org/intro\"\n  }, \"apache kafka\"), \" \"));\n}\n;\nMDXContent.isMDXComponent = true;","rawBody":"\nContent Sourced from the  [Apache Kafka](https://kafka.apache.org/intro) Website (link also provided),\n\n\n# INTRODUCTION\n\nEverything you need to know about Kafka in 10 minutes : \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FKgi3n-FyNU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n#### [Apache Kafka® is an event streaming platform. What does that mean?](https://kafka.apache.org/intro#intro_platform)\nKafka combines three key capabilities so you can implement [your use cases](https://kafka.apache.org/powered-by) for event streaming end-to-end with a single battle-tested solution:\n\n1.  To **publish** (write) and **subscribe to** (read) streams of events, including continuous import/export of your data from other systems.\n2.  To **store** streams of events durably and reliably for as long as you want.\n3.  To **process** streams of events as they occur or retrospectively.\n\nAnd all this functionality is provided in a distributed, highly scalable, elastic, fault-tolerant, and secure manner. Kafka can be deployed on bare-metal hardware, virtual machines, and containers, and on-premises as well as in the cloud. You can choose between self-managing your Kafka environments and using fully managed services offered by a variety of vendors.\n\n#### [](https://kafka.apache.org/intro#intro_nutshell)[How does Kafka work in a nutshell?](https://kafka.apache.org/intro#intro_nutshell)\n\nKafka is a distributed system consisting of **servers** and **clients** that communicate via a high-performance [TCP network protocol](https://kafka.apache.org/protocol.html). It can be deployed on bare-metal hardware, virtual machines, and containers in on-premise as well as cloud environments.\n\n**Servers**: Kafka is run as a cluster of one or more servers that can span multiple datacenters or cloud regions. Some of these servers form the storage layer, called the brokers. Other servers run [Kafka Connect](https://kafka.apache.org/documentation/#connect) to continuously import and export data as event streams to integrate Kafka with your existing systems such as relational databases as well as other Kafka clusters. To let you implement mission-critical use cases, a Kafka cluster is highly scalable and fault-tolerant: if any of its servers fails, the other servers will take over their work to ensure continuous operations without any data loss.\n\n**Clients**: They allow you to write distributed applications and microservices that read, write, and process streams of events in parallel, at scale, and in a fault-tolerant manner even in the case of network problems or machine failures. Kafka ships with some such clients included, which are augmented by [dozens of clients](https://cwiki.apache.org/confluence/display/KAFKA/Clients) provided by the Kafka community: clients are available for Java and Scala including the higher-level [Kafka Streams](https://kafka.apache.org/documentation/streams/) library, for Go, Python, C/C++, and many other programming languages as well as REST APIs.\n\n#### [What is event streaming?](https://kafka.apache.org/intro#intro_streaming)\n\nEvent streaming is the digital equivalent of the human body's central nervous system. It is the technological foundation for the 'always-on' world where businesses are increasingly software-defined and automated, and where the user of software is more software.\n\nTechnically speaking, event streaming is the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events; storing these event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in real-time as well as retrospectively; and routing the event streams to different destination technologies as needed. Event streaming thus ensures a continuous flow and interpretation of data so that the right information is at the right place, at the right time.\n\n#### [](https://kafka.apache.org/intro#intro_usage)[What can I use event streaming for?](https://kafka.apache.org/intro#intro_usage)\n\nEvent streaming is applied to a [wide variety of use cases](https://kafka.apache.org/powered-by) across a plethora of industries and organizations. Its many examples include:\n\n-   To process payments and financial transactions in real-time, such as in stock exchanges, banks, and insurances.\n-   To track and monitor cars, trucks, fleets, and shipments in real-time, such as in logistics and the automotive industry.\n-   To continuously capture and analyze sensor data from IoT devices or other equipment, such as in factories and wind parks.\n-   To collect and immediately react to customer interactions and orders, such as in retail, the hotel and travel industry, and mobile applications.\n-   To monitor patients in hospital care and predict changes in condition to ensure timely treatment in emergencies.\n-   To connect, store, and make available data produced by different divisions of a company.\n-   To serve as the foundation for data platforms, event-driven architectures, and microservices.\n\n\n#### [](https://kafka.apache.org/intro#intro_concepts_and_terms)[Main Concepts and Terminology](https://kafka.apache.org/intro#intro_concepts_and_terms)\n\nAn **event** records the fact that \"something happened\" in the world or in your business. It is also called record or message in the documentation. When you read or write data to Kafka, you do this in the form of events. Conceptually, an event has a key, value, timestamp, and optional metadata headers. Here's an example event:\n\n-   Event key: \"Alice\"\n-   Event value: \"Made a payment of $200 to Bob\"\n-   Event timestamp: \"Jun. 25, 2020 at 2:06 p.m.\"\n\n**Producers** are those client applications that publish (write) events to Kafka, and **consumers** are those that subscribe to (read and process) these events. In Kafka, producers and consumers are fully decoupled and agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for. For example, producers never need to wait for consumers. Kafka provides various [guarantees](https://kafka.apache.org/documentation/#semantics) such as the ability to process events exactly-once.\n\nEvents are organized and durably stored in **topics**. Very simplified, a topic is similar to a folder in a filesystem, and the events are the files in that folder. An example topic name could be \"payments\". Topics in Kafka are always multi-producer and multi-subscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers that subscribe to these events. Events in a topic can be read as often as needed—unlike traditional messaging systems, events are not deleted after consumption. Instead, you define for how long Kafka should retain your events through a per-topic configuration setting, after which old events will be discarded. Kafka's performance is effectively constant with respect to data size, so storing data for a long time is perfectly fine.\n\nTopics are **partitioned**, meaning a topic is spread over a number of \"buckets\" located on different Kafka brokers. This distributed placement of your data is very important for scalability because it allows client applications to both read and write the data from/to many brokers at the same time. When a new event is published to a topic, it is actually appended to one of the topic's partitions. Events with the same event key (e.g., a customer or vehicle ID) are written to the same partition, and Kafka [guarantees](https://kafka.apache.org/documentation/#semantics) that any consumer of a given topic-partition will always read that partition's events in exactly the same order as they were written.\n\n![](https://kafka.apache.org/images/streams-and-tables-p1_p4.png)\n\nFigure: This example topic has four partitions P1–P4. Two different producer clients are publishing, independently from each other, new events to the topic by writing events over the network to the topic's partitions. Events with the same key (denoted by their color in the figure) are written to the same partition. Note that both producers can write to the same partition if appropriate.\n\nTo make your data fault-tolerant and highly-available, every topic can be **replicated**, even across geo-regions or datacenters, so that there are always multiple brokers that have a copy of the data just in case things go wrong, you want to do maintenance on the brokers, and so on. A common production setting is a replication factor of 3, i.e., there will always be three copies of your data. This replication is performed at the level of topic-partitions.\n\nThis primer should be sufficient for an introduction. The [Design](https://kafka.apache.org/documentation/#design) section of the documentation explains Kafka's various concepts in full detail, if you are interested.\n \nSource: [apache kafka](https://kafka.apache.org/intro) ","excerpt":"Content Sourced from the   Apache Kafka  Website (link also provided), INTRODUCTION Everything you need to know about Kafka in 10 minutes :…","outboundReferences":[],"inboundReferences":[]},"tagsOutbound":{"nodes":[]}},"pageContext":{"tags":[],"slug":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka/","sidebarItems":[{"title":"Categories","items":[{"title":"About","url":"/About/","items":[{"title":"Old-Work-Archives","url":"","items":[{"title":"2018-Webizen-Net-Au","url":"/About/old-work-archives/2018-webizen-net-au/","items":[{"title":"about","url":"/About/old-work-archives/2018-webizen-net-au/about/","items":[]},{"title":"Consumer Protections","url":"/About/old-work-archives/2018-webizen-net-au/consumer-protections/","items":[]},{"title":"Digital Receipts","url":"/About/old-work-archives/2018-webizen-net-au/digital-receipts/","items":[]},{"title":"Fake News: Considerations → Principles → The Institution of Socio & Economic Values","url":"/About/old-work-archives/2018-webizen-net-au/fake-news-considerations/","items":[]},{"title":"HYPERMEDIA PACKAGES","url":"/About/old-work-archives/2018-webizen-net-au/hypermedia-packages/","items":[]},{"title":"Knowledge-Banking-a-Technical-Architecture-Summary","url":"","items":[{"title":"An introduction to Credentials.","url":"/About/old-work-archives/2018-webizen-net-au/knowledge-banking-a-technical-architecture-summary/what-are-credentials/","items":[]},{"title":"Personal Augmentation of AI","url":"/About/old-work-archives/2018-webizen-net-au/knowledge-banking-a-technical-architecture-summary/personal-augmentation-of-ai/","items":[]},{"title":"Semantic Inferencing","url":"/About/old-work-archives/2018-webizen-net-au/knowledge-banking-a-technical-architecture-summary/semantic-inferencing/","items":[]},{"title":"Web of Things (IoT+LD)","url":"/About/old-work-archives/2018-webizen-net-au/knowledge-banking-a-technical-architecture-summary/web-of-things-iotld/","items":[]}]},{"title":"Making the distinction between ‘privacy’ and ‘dignity’.","url":"/About/old-work-archives/2018-webizen-net-au/privacy-vs-dignity/","items":[]},{"title":"Measurements App","url":"/About/old-work-archives/2018-webizen-net-au/measurements-app/","items":[]},{"title":"Preserving The Freedom to Think","url":"/About/old-work-archives/2018-webizen-net-au/preserving-the-freedom-to-think/","items":[]},{"title":"Resource Library","url":"/About/old-work-archives/2018-webizen-net-au/resource-library/","items":[]},{"title":"Roles & Entity Analysis","url":"/About/old-work-archives/2018-webizen-net-au/roles-entity-analysis/","items":[]},{"title":"Social Informatics Design Considerations","url":"/About/old-work-archives/2018-webizen-net-au/social-informatics-design-concept-and-principles/","items":[]},{"title":"Solutions to FakeNews: Linked-Data, Ontologies and Verifiable Claims","url":"/About/old-work-archives/2018-webizen-net-au/ld-solutions-to-fakenews/","items":[]},{"title":"The need for decentralised Open (Linked) Data","url":"/About/old-work-archives/2018-webizen-net-au/the-need-for-decentralised-open-linked-data/","items":[]},{"title":"The Vision","url":"/About/old-work-archives/2018-webizen-net-au/the-vision/","items":[]},{"title":"What-Are-Credentials","url":"","items":[{"title":"credentials and custodianship","url":"/About/old-work-archives/2018-webizen-net-au/what-are-credentials/credentials-and-custodianship/","items":[]},{"title":"DIDs and MultiSig","url":"/About/old-work-archives/2018-webizen-net-au/what-are-credentials/dids-and-multisig/","items":[]}]}]},{"title":"SchemaGen Notes","url":"/About/old-work-archives/SchemaGen Notes/","items":[]},{"title":"WebCivics BizPlan 2018","url":"/About/old-work-archives/WebCivics BizPlan 2018/","items":[]},{"title":"WebCivics Medium Posts","url":"/About/old-work-archives/WebCivics Medium Posts/","items":[{"title":"A Future For Australians","url":"/About/old-work-archives/WebCivics Medium Posts/A Future For Australians/","items":[]},{"title":"A Future to Support Informed Decisions S.T.E.A.M & Stars","url":"/About/old-work-archives/WebCivics Medium Posts/A Future to Support Informed Decisions S.T.E.A.M & Stars/","items":[]},{"title":"Knowledge Clouds","url":"/About/old-work-archives/WebCivics Medium Posts/Knowledge Clouds/","items":[]},{"title":"Micropayments Standards - An Economic Imperative for the Knowledge Age","url":"/About/old-work-archives/WebCivics Medium Posts/Micropayments Standards - An Economic Imperative for the Knowledge Age/","items":[]},{"title":"Open Data v3.0 Permissive Commons","url":"/About/old-work-archives/WebCivics Medium Posts/Open Data v3.0 Permissive Commons/","items":[]},{"title":"Skills & Social Activities","url":"/About/old-work-archives/WebCivics Medium Posts/Skills & Social Activities/","items":[]},{"title":"Small to Medium Business, WebPayments & Knowledge Banking","url":"/About/old-work-archives/WebCivics Medium Posts/Small to Medium Business, WebPayments & Knowledge Banking/","items":[]},{"title":"Tech for Permissive Commons","url":"/About/old-work-archives/WebCivics Medium Posts/Tech for Permissive Commons/","items":[]},{"title":"The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech.","url":"/About/old-work-archives/WebCivics Medium Posts/The Semantic Inforg & The “Human Centric Web” — Reality Check, Tech./","items":[]},{"title":"Tooling for Democracies","url":"/About/old-work-archives/WebCivics Medium Posts/Tooling for Democracies/","items":[]},{"title":"WoT Smart Cities Engineering Digital Twin Things & Ecosystems.","url":"/About/old-work-archives/WebCivics Medium Posts/WoT Smart Cities Engineering Digital Twin Things & Ecosystems./","items":[]}]},{"title":"Webizen Group 2015","url":"/About/old-work-archives/Webizen Group 2015/","items":[]}]},{"title":"Ontology Modelling","url":"/About/Ontology Modelling/","items":[]},{"title":"Understanding Ontologies","url":"/About/Understanding Ontologies/","items":[]},{"title":"Web Science","url":"/About/Web Science/","items":[]}]},{"title":"Documentation Method","url":"/Documentation Method/","items":[]},{"title":"Existing Ecosystems","url":"/Existing Ecosystems/","items":[{"title":"DIDs","url":"/Existing Ecosystems/DIDs/","items":[]},{"title":"Non-HTTP(s) Protocols","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/","items":[{"title":"Chia","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/Chia/","items":[]},{"title":"DAT","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/DAT/","items":[]},{"title":"GIT","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/GIT/","items":[]},{"title":"GUNECO","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/GUNECO/","items":[]},{"title":"Hedera","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/Hedera/","items":[]},{"title":"IOTA","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/IOTA/","items":[]},{"title":"IPFS","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/IPFS/","items":[]},{"title":"Lightning Network","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/Lightning Network/","items":[]},{"title":"NYM","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/NYM/","items":[]},{"title":"Obyte","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/obyte/","items":[]},{"title":"WebRTC","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/WebRTC/","items":[]},{"title":"WebSockets","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/WebSockets/","items":[]},{"title":"WebTorrent","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/WebTorrent/","items":[]},{"title":"WireGuard","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/WireGuard/","items":[]},{"title":"XRP Ledger","url":"/Existing Ecosystems/Non-HTTP(s) Protocols/XRP Ledger/","items":[]}]},{"title":"Open Badges","url":"/Existing Ecosystems/Open Badges/","items":[]},{"title":"Semantic Web","url":"/Existing Ecosystems/Semantic Web/","items":[{"title":"Ontologies","url":"/Existing Ecosystems/Semantic Web/Ontologies/","items":[{"title":"FOAF","url":"/Existing Ecosystems/Semantic Web/Ontologies/FOAF/","items":[]},{"title":"Human Rights Ontologies","url":"","items":[{"title":"UDHR","url":"/Existing Ecosystems/Semantic Web/Ontologies/Human Rights Ontologies/UDHR/","items":[]}]},{"title":"MD-RDF Ontologies","url":"","items":[{"title":"DataTypesOntology (DTO) Core","url":"/Existing Ecosystems/Semantic Web/Ontologies/MD-RDF Ontologies/DataTypes Ontology/","items":[]},{"title":"Friend of a Friend (FOAF) Core","url":"/Existing Ecosystems/Semantic Web/Ontologies/MD-RDF Ontologies/FOAF/","items":[]}]},{"title":"OWL","url":"/Existing Ecosystems/Semantic Web/Ontologies/OWL/","items":[]},{"title":"RDFS","url":"/Existing Ecosystems/Semantic Web/Ontologies/RDFS/","items":[]},{"title":"Sitemap","url":"/Existing Ecosystems/Semantic Web/Ontologies/Sitemap/","items":[]},{"title":"SKOS","url":"/Existing Ecosystems/Semantic Web/Ontologies/SKOS/","items":[]},{"title":"SOIC","url":"/Existing Ecosystems/Semantic Web/Ontologies/SOIC/","items":[]}]},{"title":"Sparql","url":"","items":[{"title":"Sparql Family","url":"/Existing Ecosystems/Semantic Web/Sparql/Sparql Family/","items":[]}]},{"title":"W3C Specifications","url":"","items":[{"title":"Linked Data Fragments","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Linked Data Fragments/","items":[]},{"title":"Linked Data Notifications","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Linked Data Notifications/","items":[]},{"title":"Linked Data Platform","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Linked Data Platform/","items":[]},{"title":"Linked Media Fragments","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Linked Media Fragments/","items":[]},{"title":"RDF","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/RDF/","items":[]},{"title":"Web Access Control (WAC)","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Web Access Control (WAC)/","items":[]},{"title":"Web Of Things","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/Web Of Things/","items":[]},{"title":"WebID Specifications","url":"/Existing Ecosystems/Semantic Web/W3C Specifications/WebID Specifications/","items":[]}]}]},{"title":"Verifiable Claims & Credentials","url":"/Existing Ecosystems/Verifiable Claims & Credentials/","items":[]},{"title":"Verifiable Credentials","url":"/Existing Ecosystems/Verifiable Credentials/","items":[]}]},{"title":"Permissive Commons","url":"/Permissive Commons/","items":[{"title":"Permissive Commons Tech","url":"/Permissive Commons/Permissive Commons Tech/","items":[]}]},{"title":"Permissive Commons Ontologies Docs","url":"/","items":[]},{"title":"Requirements","url":"/Requirements/","items":[{"title":"Business-Cases","url":"/Requirements/Business-Cases/","items":[]},{"title":"Decentralised Ontologies","url":"/Requirements/Decentralised Ontologies/","items":[]},{"title":"Engineering Considerations","url":"/Requirements/Engineering Considerations/","items":[{"title":"Science of Consciousness","url":"/Requirements/Engineering Considerations/Science of Consciousness/","items":[]},{"title":"Temporal Semantics","url":"/Requirements/Engineering Considerations/Temporal Semantics/","items":[]}]},{"title":"PCT-Core-Services","url":"/Requirements/PCT-Core-Services/","items":[]}]},{"title":"Use Cases","url":"/use-cases/","items":[{"title":"Peace Infrastructure Project","url":"/use-cases/Peace Infrastructure Project/","items":[{"title":"About the Peace Infrastructure Project","url":"/use-cases/Peace Infrastructure Project/About the Peace Infrastructure Project/","items":[]},{"title":"Background","url":"/use-cases/Peace Infrastructure Project/The Values Project/","items":[]},{"title":"Biosphere Ontologies","url":"/use-cases/Peace Infrastructure Project/Biosphere Ontologies/","items":[]},{"title":"Content","url":"/use-cases/Peace Infrastructure Project/Value Accounting Initiatives/","items":[]},{"title":"Environmental, Social and Governance (ESG)","url":"/use-cases/Peace Infrastructure Project/ESG/","items":[{"title":"Biosphere Calcs","url":"/use-cases/Peace Infrastructure Project/ESG/Biosphere Calcs/","items":[]},{"title":"Energy Calcs","url":"/use-cases/Peace Infrastructure Project/ESG/Energy Calcs/","items":[]},{"title":"SocioSphere Calcs","url":"/use-cases/Peace Infrastructure Project/ESG/SocioSphere Calcs/","items":[]}]},{"title":"Safety Protocols","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/","items":[{"title":"Data Portability","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Data Portability/","items":[]},{"title":"Ending Digital Slavery","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Ending Digital Slavery/","items":[]},{"title":"Fair Work Protocols","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Fair Work Protocols/","items":[]},{"title":"Freedom of Thought","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Freedom of Thought/","items":[]},{"title":"Human Centric AI","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Human Centric AI/","items":[]},{"title":"HumanCentric Digital Identity","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/HumanCentric Digital Identity/","items":[]},{"title":"No Lock-Ins","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/No Lock-ins/","items":[]},{"title":"Relationships (Social)","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Relationships (Social)/","items":[]},{"title":"Values Credentials","url":"/use-cases/Peace Infrastructure Project/Safety Protocols/Values Credentials/","items":[]}]},{"title":"Social Attack Vectors","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/","items":[{"title":"Attacks Online","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Attacks Online/","items":[]},{"title":"Criminal Activity","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Criminal Activity/","items":[{"title":"Corporate Crime","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Criminal Activity/Corporate Crime/","items":[]},{"title":"Cyber Crime","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Criminal Activity/Cyber Crime/","items":[]},{"title":"Financial Crimes","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Criminal Activity/Financial Crimes/","items":[]},{"title":"Fraud","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Criminal Activity/Fraud/","items":[]}]},{"title":"Public Sector Wrong Doings","url":"/use-cases/Peace Infrastructure Project/Social Attack Vectors/Public Sector Wrong Doings/","items":[]}]},{"title":"SocioSphere Ontologies","url":"/use-cases/Peace Infrastructure Project/SocioSphere Ontologies/","items":[]},{"title":"Sustainable Development Goals (ESG)","url":"/use-cases/Peace Infrastructure Project/Sustainable Development Goals (ESG)/","items":[]}]},{"title":"Webizen","url":"/use-cases/Webizen/","items":[{"title":"Economic Systems","url":"/use-cases/Webizen/Economic Systems/","items":[{"title":"Centricity","url":"/use-cases/Webizen/Economic Systems/Centricity/","items":[]},{"title":"Currencies","url":"/use-cases/Webizen/Economic Systems/Currencies/","items":[{"title":"Financial Payment Types","url":"/use-cases/Webizen/Economic Systems/Currencies/Financial Payment Types/","items":[]},{"title":"Gifts and Donations","url":"/use-cases/Webizen/Economic Systems/Currencies/Gifts and Donations/","items":[]},{"title":"Micropayments","url":"/use-cases/Webizen/Economic Systems/Currencies/Micropayments/","items":[]},{"title":"Non-Financial Currencies","url":"/use-cases/Webizen/Economic Systems/Currencies/Non-Financial Currencies/","items":[]}]},{"title":"The Work Project","url":"/use-cases/Webizen/Economic Systems/WorkProject/","items":[{"title":"Contribution Classifications","url":"/use-cases/Webizen/Economic Systems/WorkProject/Contribution Classifications/","items":[]},{"title":"Equipment and Supplies","url":"/use-cases/Webizen/Economic Systems/WorkProject/Equipment and Supplies/","items":[]},{"title":"Intellectual Property","url":"/use-cases/Webizen/Economic Systems/WorkProject/Intellectual Property/","items":[]},{"title":"Knowledge Work","url":"/use-cases/Webizen/Economic Systems/WorkProject/Knowledge Work/","items":[]},{"title":"Labour Work","url":"/use-cases/Webizen/Economic Systems/WorkProject/Labour Work/","items":[]},{"title":"Licensing Frameworks","url":"/use-cases/Webizen/Economic Systems/WorkProject/Licensing Frameworks/","items":[]},{"title":"Project Financing","url":"/use-cases/Webizen/Economic Systems/WorkProject/Project Financing/","items":[]},{"title":"Resources","url":"/use-cases/Webizen/Economic Systems/WorkProject/Resources/","items":[]},{"title":"Work Valuation Methods","url":"/use-cases/Webizen/Economic Systems/WorkProject/Work Valuation Methods/","items":[]}]},{"title":"Webizen Alliance","url":"/use-cases/Webizen/Economic Systems/Webizen Alliance/","items":[{"title":"Community of Practice","url":"/use-cases/Webizen/Economic Systems/Webizen Alliance/Community of Practice/","items":[]},{"title":"The Webizen Charter","url":"/use-cases/Webizen/Economic Systems/Webizen Alliance/The Webizen Charter/","items":[]}]}]},{"title":"Host Service Requirements","url":"","items":[{"title":"Authentication Fabric","url":"/use-cases/Webizen/Host Service Requirements/Authentication Fabric/","items":[]},{"title":"Database Requirements","url":"","items":[{"title":"Database Alternatives","url":"","items":[{"title":"Akutan","url":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/akutan/","items":[]},{"title":"CayleyGraph","url":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/CayleyGraph/","items":[]},{"title":"INTRODUCTION","url":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database Alternatives/Apache Kafka/","items":[]}]},{"title":"Database Methods","url":"","items":[{"title":"GraphQL","url":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database methods/GraphQL/","items":[]},{"title":"Sparql","url":"/use-cases/Webizen/Host Service Requirements/Database requirements/Database methods/Sparql/","items":[]}]}]},{"title":"Domain Hosting","url":"/use-cases/Webizen/Host Service Requirements/Domain Hosting/","items":[]},{"title":"Email Services","url":"/use-cases/Webizen/Host Service Requirements/Email Services/","items":[]},{"title":"Media Processing","url":"/use-cases/Webizen/Host Service Requirements/Media Processing/","items":[{"title":"Ffmpeg","url":"/use-cases/Webizen/Host Service Requirements/Media Processing/ffmpeg/","items":[]},{"title":"Opencv","url":"/use-cases/Webizen/Host Service Requirements/Media Processing/opencv/","items":[]}]},{"title":"Networking Considerations","url":"/use-cases/Webizen/Host Service Requirements/Networking Considerations/","items":[]},{"title":"Website Host","url":"/use-cases/Webizen/Host Service Requirements/Website Host/","items":[]}]},{"title":"HyperMedia Containers","url":"/use-cases/Webizen/HyperMedia Containers/","items":[]},{"title":"HyperMediaContainers","url":"","items":[{"title":"Knowledge Documents","url":"/use-cases/Webizen/HyperMediaContainers/Knowledge Documents/","items":[]},{"title":"Webizen 3.0 Apps","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/","items":[{"title":"Core Apps","url":"","items":[{"title":"Agent Directory","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Agent Directory/","items":[]},{"title":"Credentials & Contracts Manager","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Credentials & Contracts Manager/","items":[]},{"title":"File (Package) Manager","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/File (package) Manager/","items":[]},{"title":"HyperMedia Library","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/HyperMedia Library/","items":[]},{"title":"Temporal Apps","url":"","items":[{"title":"Calendar","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Temporal Apps/Calendar/","items":[]},{"title":"Timeline Interface","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Temporal Apps/Timeline Interface/","items":[]}]},{"title":"Webizen Apps (V1)","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Webizen Apps (v1)/","items":[]},{"title":"Webizen Manager","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Webizen Manager/","items":[]}]},{"title":"Design Goals","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Design Goals/","items":[]},{"title":"Webizen-Connect","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Webizen-Connect/","items":[{"title":"Data Applications","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Webizen-Connect/Data Applications/","items":[]},{"title":"Social Media APIs","url":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Webizen-Connect/Social Media APIs/","items":[]}]}]}]},{"title":"PCT-Webizen Tech Stack","url":"/use-cases/Webizen/PCT-Webizen Tech Stack/","items":[]},{"title":"Social Ontology","url":"","items":[{"title":"Best Efforts","url":"/use-cases/Webizen/Social Ontology/Best Efforts/","items":[]},{"title":"Fit For Purpose","url":"/use-cases/Webizen/Social Ontology/Fit For Purpose/","items":[]},{"title":"Learning Modals","url":"/use-cases/Webizen/Social Ontology/Learning Modals/","items":[]}]}]}]},{"title":"Work in Progress","url":"/Work in Progress/","items":[]}]}],"tagsGroups":[],"latestPosts":[{"fields":{"slug":"/use-cases/Peace Infrastructure Project/Sustainable Development Goals (ESG)/","title":"Sustainable Development Goals (ESG)","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/use-cases/Webizen/Host Service Requirements/Email Services/","title":"Email Services","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Credentials & Contracts Manager/","title":"Credentials & Contracts Manager","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/File (package) Manager/","title":"File (Package) Manager","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Webizen Apps (v1)/","title":"Webizen Apps (V1)","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/use-cases/Webizen/HyperMediaContainers/Webizen 3.0 apps/Core Apps/Webizen Manager/","title":"Webizen Manager","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/About/","title":"About","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Documentation Method/","title":"Documentation Method","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Existing Ecosystems/","title":"Existing Ecosystems","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}},{"fields":{"slug":"/Permissive Commons/","title":"Permissive Commons","lastUpdatedAt":"2023-01-04T00:28:43.000Z","lastUpdated":"1/4/2023"},"frontmatter":{"draft":false,"tags":[]}}]}},
    "staticQueryHashes": ["2230547434","2320115945","3495835395","451533639"]}